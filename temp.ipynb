{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv() #WARNING: This will load the .env file in the current directory\n",
    "\n",
    "POSTGRES_HOST = os.getenv(\"POSTGRES_HOST\")\n",
    "POSTGRES_PORT = os.getenv(\"POSTGRES_PORT\")\n",
    "POSTGRES_DB_NAME = os.getenv(\"POSTGRES_DB\")\n",
    "POSTGRES_USER = os.getenv(\"POSTGRES_USER\")\n",
    "POSTGRES_PASSWORD = os.getenv(\"POSTGRES_PASSWORD\")\n",
    "CONTAINER_NAME = os.getenv(\"CONTAINER_NAME\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'host=None port=None dbname=None user=None password=None'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_psycopg3_connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = PostgresDataSource()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "invalid integer value \"None\" for connection option \"port\"\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOperationalError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43msource\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_timeseries\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlat\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m37.7749\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlon\u001b[49m\u001b[43m=\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m122.4194\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/akk/learning/Pofortlio/ClimdexDash/src/data/source.py:82\u001b[39m, in \u001b[36mPostgresDataSource.get_timeseries\u001b[39m\u001b[34m(self, lat, lon)\u001b[39m\n\u001b[32m     68\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_timeseries\u001b[39m(\u001b[38;5;28mself\u001b[39m, lat: \u001b[38;5;28mfloat\u001b[39m, lon: \u001b[38;5;28mfloat\u001b[39m) -> pd.DataFrame:\n\u001b[32m     69\u001b[39m     query = \u001b[33m\"\"\"\u001b[39m\n\u001b[32m     70\u001b[39m \u001b[33m    WITH nearest_location AS (\u001b[39m\n\u001b[32m     71\u001b[39m \u001b[33m        SELECT latitude, longitude, location_id\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m     79\u001b[39m \u001b[33m    ORDER BY w.time;\u001b[39m\n\u001b[32m     80\u001b[39m \u001b[33m    \u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mpsycopg2\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconnection_string\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m conn:\n\u001b[32m     83\u001b[39m         df = pd.read_sql(query, conn, params=(lat, lon))\n\u001b[32m     84\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/akk/learning/Pofortlio/ClimdexDash/.venv/lib/python3.12/site-packages/psycopg2/__init__.py:122\u001b[39m, in \u001b[36mconnect\u001b[39m\u001b[34m(dsn, connection_factory, cursor_factory, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m     kwasync[\u001b[33m'\u001b[39m\u001b[33masync_\u001b[39m\u001b[33m'\u001b[39m] = kwargs.pop(\u001b[33m'\u001b[39m\u001b[33masync_\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    121\u001b[39m dsn = _ext.make_dsn(dsn, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m conn = \u001b[43m_connect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdsn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconnection_factory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconnection_factory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwasync\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cursor_factory \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    124\u001b[39m     conn.cursor_factory = cursor_factory\n",
      "\u001b[31mOperationalError\u001b[39m: invalid integer value \"None\" for connection option \"port\"\n"
     ]
    }
   ],
   "source": [
    "source.get_timeseries(lat=37.7749, lon=-122.4194)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    time  total_precipitation\n",
      "0    2022-01-01 00:00:00         0.000000e+00\n",
      "1    2022-01-01 01:00:00         7.192290e-04\n",
      "2    2022-01-01 02:00:00         1.438458e-03\n",
      "3    2022-01-01 03:00:00         2.157686e-03\n",
      "4    2022-01-01 04:00:00         2.876912e-03\n",
      "...                  ...                  ...\n",
      "8732 2022-12-30 20:00:00        -2.876912e-03\n",
      "8733 2022-12-30 21:00:00        -2.157686e-03\n",
      "8734 2022-12-30 22:00:00        -1.438458e-03\n",
      "8735 2022-12-30 23:00:00        -7.192290e-04\n",
      "8736 2022-12-31 00:00:00        -2.449294e-16\n",
      "\n",
      "[8737 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yh/g08b7w3d411gn1p_cp_409ym0000gn/T/ipykernel_40210/3438745503.py:83: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn, params=(lat, lon))\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional\n",
    "from abc import ABC, abstractmethod\n",
    "import psycopg2\n",
    "import os\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv() #WARNING: This will load the .env file in the current directory\n",
    "\n",
    "POSTGRES_HOST = os.getenv(\"POSTGRES_HOST\")\n",
    "POSTGRES_PORT = os.getenv(\"POSTGRES_PORT\")\n",
    "POSTGRES_DB_NAME = os.getenv(\"POSTGRES_DB\")\n",
    "POSTGRES_USER = os.getenv(\"POSTGRES_USER\")\n",
    "POSTGRES_PASSWORD = os.getenv(\"POSTGRES_PASSWORD\")\n",
    "CONTAINER_NAME = os.getenv(\"CONTAINER_NAME\")\n",
    "\n",
    "\n",
    "\n",
    "def get_psycopg3_connection():\n",
    "    connection_string = (\n",
    "        f\"host={POSTGRES_HOST} \"\n",
    "        f\"port={POSTGRES_PORT} \"\n",
    "        f\"dbname={POSTGRES_DB_NAME} \"\n",
    "        f\"user={POSTGRES_USER} \"\n",
    "        f\"password={POSTGRES_PASSWORD}\"\n",
    "    )\n",
    "    return connection_string\n",
    "\n",
    "def fake_timeseries_data() -> pd.DataFrame:\n",
    "    \"\"\"using numpy to generate Sine wave data for a year at hourly intervals\"\"\"\n",
    "    time = pd.date_range(start=\"2022-01-01\", end=\"2022-12-31\", freq=\"h\")\n",
    "    data = np.sin(np.linspace(0, 2 * np.pi, len(time)))\n",
    "    return pd.DataFrame({\"time\": time, \"total_precipitation\": data})\n",
    "\n",
    "\n",
    "# Abstract Strategy\n",
    "class DataSource(ABC):\n",
    "    @abstractmethod\n",
    "    def get_timeseries(self, lat: float, lon: float) -> pd.DataFrame:\n",
    "        pass\n",
    "\n",
    "# Concrete Strategy - CSV File Source\n",
    "@dataclass\n",
    "class CSVFileSource(DataSource):\n",
    "    file_path: str\n",
    "\n",
    "    def __post_init__(self):\n",
    "        # self.data = pd.read_csv(self.file_path)\n",
    "        self.data = fake_timeseries_data()\n",
    "\n",
    "    def get_timeseries(self, lat: float, lon: float) -> pd.DataFrame:\n",
    "        # df_filtered = self.data[(self.data[\"latitude\"] == lat) & (self.data[\"longitude\"] == lon)]\n",
    "        df_filtered = self.data\n",
    "        return df_filtered.sort_values(by=\"time\")\n",
    "\n",
    "# Concrete Strategy - Postgres Data Source\n",
    "@dataclass\n",
    "class PostgresDataSource(DataSource):\n",
    "    connection_string: Optional[str] = None\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.connection_string = get_psycopg3_connection()\n",
    "\n",
    "    def get_timeseries(self, lat: float, lon: float) -> pd.DataFrame:\n",
    "        query = \"\"\"\n",
    "        WITH nearest_location AS (\n",
    "            SELECT latitude, longitude, location_id\n",
    "            FROM weather\n",
    "            ORDER BY (latitude - %s)^2 + (longitude - %s)^2\n",
    "            LIMIT 1\n",
    "        )\n",
    "        SELECT DISTINCT ON (w.time) w.time, w.total_precipitation, w.latitude, w.longitude, w.location_id\n",
    "        FROM weather w\n",
    "        JOIN nearest_location nl ON w.location_id = nl.location_id\n",
    "        ORDER BY w.time;\n",
    "        \"\"\"\n",
    "        \n",
    "        with psycopg2.connect(self.connection_string) as conn:\n",
    "            df = pd.read_sql(query, conn, params=(lat, lon))\n",
    "        return df\n",
    "\n",
    "# Concrete Strategy - netCDF File Source\n",
    "@dataclass\n",
    "class NetCDFFileSource(DataSource):\n",
    "    file_path: str\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.data = fake_timeseries_data()\n",
    "\n",
    "    def get_timeseries(self, lat: float, lon: float) -> pd.DataFrame:\n",
    "        # Read netCDF file and extract data\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Context Class to Use Different Strategies\n",
    "@dataclass\n",
    "class TimeSeriesFetcher:\n",
    "    data_source: DataSource\n",
    "\n",
    "    def get_data(self, lat: float, lon: float) -> pd.DataFrame:\n",
    "        return self.data_source.get_timeseries(lat, lon)\n",
    "\n",
    "# Example Usage\n",
    "if __name__ == \"__main__\":\n",
    "    # CSV Example\n",
    "    csv_source = CSVFileSource(\"data.csv\")\n",
    "    fetcher = TimeSeriesFetcher(csv_source)\n",
    "    print(fetcher.get_data(40.7128, -74.0060))\n",
    "    \n",
    "    # Postgres Example\n",
    "    pg_source = PostgresDataSource(\"dbname=test user=postgres password=secret host=localhost\")\n",
    "    fetcher = TimeSeriesFetcher(pg_source)\n",
    "    print(fetcher.get_data(40.7128, -74.0060))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
